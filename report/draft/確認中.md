





  
### 物体認識タスクの分類

| タスク                                | 出力                                         |
| ------------------------------------- | -------------------------------------------- |
| 分類（Classification）                | クラスラベル                                 |
| 物体検知（Object Detection）          | Bounding Box + クラス + 信頼度（Confidence） |
| 意味領域分割（Semantic Segmentation） | 各ピクセルに対するクラスラベル               |
| 個体領域分割（Instance Segmentation） | 各物体に対して独立したピクセルラベリング     |

## 物体検知の評価指標

### IoU（Intersection over Union）

$$
\text{IoU} = \frac{\text{Area of Overlap}}{\text{Area of Union}}
$$

- **Overlap**: 予測と正解の共通部分
- **Union**: 予測と正解の和集合
- IoUとConfidenceの両方に閾値を設けて精度を評価

### Precision-Recall曲線
- Confidenceの閾値を変化させてPR曲線を描く
- **AP（Average Precision）**: PR曲線の下側の面積
- **mAP（mean AP）**: クラスごとのAPを平均

---

## 物体検出の代表的フレームワーク

### 2段階検出器（例：RCNN）
- 候補領域抽出と分類を別々に行う
- **高精度だが計算コスト大**

### 1段階検出器（例：YOLO）
- 候補抽出と分類を同時に行う
- **高速だがやや精度低**

---

## SSD（Single Shot Detector）

- ベースモデル：VGG16
- **マルチスケール特徴マップ** を利用
  - 大：小さい物体の検出
  - 小：大きい物体の検出

### 出力形式
- 各特徴マップから $k \times (\text{クラス数} + 4)$ を出力
  - 4：Bounding Boxのオフセット（$\Delta x, \Delta y, \Delta w, \Delta h$）

### 対処手法
- **Non-Maximum Suppression (NMS)**: 重複検出排除
- **Hard Negative Mining**: 背景クラスのバランス調整

---

## Semantic Segmentation

- 各ピクセルに対してクラスラベルを予測
- Upsampling（解像度復元）が必要

### 技術要素

- **Deconvolution / Transposed Convolution**
  - stride を挟んで特徴マップを拡張
- **FCN（Fully Convolutional Network）**
  - 低層の特徴と高層の特徴を合成して輪郭などを補完

### その他

- **Dilated Convolution**
  - フィルター内のピクセル間隔を空けて畳み込み
  - 同じカーネルサイズでも広い受容野を確保可能

# Instance Segmentation

## 概要

- **Instance Segmentation（個体領域分割）** は、Semantic Segmentation に加えて、同一クラス内で個別のオブジェクト（インスタンス）を識別するタスク。
- 各ピクセルに **クラスID + インスタンスID** を付与する。

---

## 代表的な手法

### ✅ YOLACT（You Only Look At CoefficienTs）

- **ワンステップ**でインスタンスセグメンテーションを実現。
- 軽量かつリアルタイム処理に向いている。

---

### ✅ Mask R-CNN

- **Faster R-CNN** をベースにした拡張モデル。
- バウンディングボックス領域ごとに**ピクセル単位のマスク出力**を追加。

---

## R-CNNファミリーの進化

### 🧱 R-CNN

- 関心領域 (RoI) を **Selective Search** によって抽出。
- 各RoIをサイズ統一 → CNNで特徴抽出 → SVMでクラス分類。
- 精度は高いが **非常に遅い**。

---

### ⚡ Fast R-CNN

- 入力画像に1度だけCNNを適用し、得られた特徴マップを利用してRoIを抽出。
- **畳み込みの再利用**で高速化。

---

### ⚡ Faster R-CNN

- **Region Proposal Network (RPN)** を導入。
- RoI候補の提案もCNNで処理可能に。
- **End-to-End学習**可能で高速・高精度。

---

## YOLO（You Only Look Once）

- **物体検出とクラス分類を一つのネットワークで同時に実行**。
- 画像全体を $S \times S$ グリッドに分割し、各グリッドから $B$ 個のバウンディングボックスを予測。
- **非常に高速**だが、Faster R-CNNに比べて**やや精度が劣る**。

---

## FCOS（Fully Convolutional One-Stage Object Detection）

- **アンカーフリー**の物体検出手法。
- アンカーボックスのハイパーパラメータ設定不要。
- 画像内の **全ピクセル**から物体位置（4次元ベクトル）を直接予測。

---

## Feature Pyramid Networks（FPN）

- **マルチスケールの特徴マップ**を生成。
  - 高解像度層：小さい物体に強い
  - 低解像度層：意味的特徴に強い
- 重なった物体の処理に強い。

---

## Mask R-CNN の構造

- Faster R-CNN に **マスク出力の分岐を追加**。
- RoI毎にマスク（ピクセル分類）を出力。
- **RoI Align** により RoI Pooling の精度問題を改善。
  - 特徴マップの補間処理により位置ズレを軽減。

---

## RoI Pooling vs RoI Align

| 手法        | 特徴                                         |
| ----------- | -------------------------------------------- |
| RoI Pooling | 固定サイズに間引き、**高速だがズレが生じる** |
| RoI Align   | 補間処理でズレを抑える、**精度向上**         |

---

このように、インスタンスセグメンテーションでは **物体の位置・クラス・形状（マスク）** を同時に扱うため、高精度での位置合わせやスケール対応が重要になります。

# GAN（Generative Adversarial Networks）とその拡張

## Discriminatorの更新戦略

- 通常、**Discriminatorの更新を複数回**行ってから、**Generatorの更新を1回**行う（毎回ペアではない）。
- **理想状態**：
  - 生成データと真データが区別できないほど類似している。
  - このとき価値関数は最適化され、Generatorの損失は**最小値**になる。

---

## DCGAN（Deep Convolutional GAN）

### Generator
- Poolingの代わりに **Transposed Convolution**（アップサンプリング）
- 最終層は `tanh`（出力範囲：-1〜1）
- 中間層は `ReLU` を使用

### Discriminator
- Poolingの代わりに **Convolution**
- `Leaky ReLU` を活性化関数に使用
- 最終層は `sigmoid`（出力範囲：0〜1）

### 共通点
- **全結合層なし**
- **Batch Normalization** を導入し学習を安定化

---

## 応用技術：顔アバター生成

- 「1枚の顔画像」から「動くアバター」を生成
- 初期化部（高コスト）と推論部（軽量）で構成
- 輪郭と顔画像を別々に生成・結合して高速化

---

## Conditional GAN（CGAN）

- 生成するデータに**条件（ラベル）**を追加
- GeneratorとDiscriminatorの両方に条件を与える
- 例：「犬」ラベルで犬の画像を生成

---

## Pix2Pix

- CGANの発展：**条件を画像に**
- 入力画像 $x$ に対応する変換後画像 $y$ を学習
- Generator: **U-Net**
- Discriminator: **PatchGAN**（画像のパッチごとに分類）

### 損失関数
- GAN損失 + **L1正則化**
- 高周波情報（エッジなど）を学習させ、ぼやけを防止

---

# 深層強化学習：A3C, A2C

## A3C（Asynchronous Advantage Actor-Critic）

### 特徴
- 複数エージェントが**非同期並列学習**
- 各エージェントが自律的に学習し、**パラメータサーバー**を更新
- 定期的にパラメータを同期

### メリット
- 学習が高速かつ安定
- 経験の**自己相関を軽減**

### ロス関数
- アドバンテージ方策勾配
- 価値関数ロス
- 方策エントロピー

---

## A2C（Advantage Actor-Critic）

- A3Cの**同期バージョン**
- Pythonなどでの実装がしやすく、性能もA3Cに匹敵

---

# Deep Metric Learning

## Siamese Network
- 入力：2つのデータ
- 同一クラスなら距離を縮め、異なるクラスなら距離を離す
- **Contrastive Loss** を使用

## Triplet Network
- 入力：Anchor + Positive + Negative
- **Triplet Loss**：
  - $D(a, p) + \text{margin} < D(a, n)$ を満たすように学習
- より安定した**埋め込み空間**の学習が可能

---

# MAML（Model-Agnostic Meta-Learning）

- 少数データでもモデルを高速に適応させる学習手法
- 共通重み $\theta$ を様々なタスクでの内的最適化結果から更新（Outer Loop）

---

# GCN（Graph Convolutional Network）

- グラフ構造に対する畳み込み処理
- **Spatialアプローチ**（局所構造の繰り返し処理）
- **Spectralアプローチ**（グラフフーリエ変換）

---

# 深層学習の説明性

## CAM（Class Activation Mapping）
- GAPを活用して画像の注目領域を可視化

## Grad-CAM
- 勾配ベースで重要領域を視覚化
- **GAP不要、分類タスク以外にも適用可**

## LIME
- 単一予測を局所線形モデルで近似して説明

## SHAP
- Shapley値による特徴量の**平均的貢献度**を計算

---

# 開発・運用環境

## Docker
- 軽量な**コンテナ仮想化**
- 開発/テスト/本番環境の統一と迅速化を実現

---

# バッチ正規化と代替手法

## Batch Normalization
- ミニバッチごとに平均・分散を調整
- **ミニバッチが小さいと効果低減**

## 代替手法
- **Layer Normalization**：全ピクセルに対して正規化
- **Instance Normalization**：チャネルごとに正規化
  - 画像スタイル変換やテクスチャ合成で有効

---

# 参考文献

- 『ディープラーニング入門 Chainerチュートリアル』
- 『ゼロから作るDeep Learning』シリーズ
- 『機械学習のエッセンス』
- 『ディープラーニングE資格エンジニア問題集』

